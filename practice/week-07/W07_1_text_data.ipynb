{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIG DATA ANALYTICS  : Text data preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "konlpy를 활용한 text data 전처리에 대해서 실습해보겠습니다.\n",
    "- (Konlpy 실행을 위해) JAVA가 설치되어 있어야 실행가능한 노트북 파일입니다.\n",
    "- JAVA가 설치되지 않으신 분은 다음 링크를 통해서 설치해주세요\n",
    "    - https://www.java.com/ko/download/\n",
    "\n",
    "- 오늘 실습에서는 다음 링크를 통해서 진행하겠습니다.\n",
    "    - https://colab.research.google.com/drive/17yCp8swO_0eu4kunifKWOUI4jw1HMPg6#offline=true&sandboxMode=true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#관련 라이브러리 설치\n",
    "import sys\n",
    "!{sys.executable} -m pip install newspaper3k konlpy sklearn pandas\n",
    "!pip install newspaper3k konlpy sklearn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 텍스트 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "url = 'https://ko.wikipedia.org/wiki/%EA%B9%80%EC%97%B0%EC%95%84'\n",
    "news = Article(url, language='ko')\n",
    "news.download()\n",
    "news.parse()\n",
    "text = news.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 문장 단위 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text.split(\"\\n\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tokenzation\n",
    "- 원형복원, 불용어제거, 품사별 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "# tokenizer : 문장에서 색인어 추출을 위해 명사,동사,알파벳,숫자 정도의 단어만 뽑아서 normalization, stemming 처리하도록 함\n",
    "def tokenizer(raw, pos=[\"Noun\"], stopword=[\"경기\",\"선수\",\"기록\",\"라운드\",\"대한민국\",\"한국\",\"시즌\",\"세계\",\"선정\",\"편집\"]):\n",
    "    return [\n",
    "        word for word, tag in okt.pos(\n",
    "            raw, \n",
    "            norm=True,   # normalize 그랰ㅋㅋ -> 그래ㅋㅋ\n",
    "            stem=True    # stemming 바뀌나->바뀌다\n",
    "            )\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for sentence in sentences :\n",
    "    parsed_version = tokenizer(sentence)\n",
    "    if parsed_version:\n",
    "        docs.append(\" \".join(parsed_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 빈도수 기반의 Matrix화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
