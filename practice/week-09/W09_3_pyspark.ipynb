{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIG DATA ANALYTICS PROGRAMMING : PySpark\n",
    "### PySpark 맛보기\n",
    "\n",
    "- JAVA 설치가 필요한 과정이므로, 문제가 있으신 분들은 다음 링크에서 작업해주세요!\n",
    "- https://colab.research.google.com/drive/13mngg3qXnBKm-pH82o6Dfw3HMikUN3p2#offline=true&sandboxMode=true\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYSPARK를 활용하기 위한 관련 설정\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"]=sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=sys.executable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD 활용하기\n",
    "- Resilient Disributed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark 임포트\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark context를 활용해 RDD를 생성 할 수 있다\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile example.txt\n",
    "first line\n",
    "second line\n",
    "third line\n",
    "fourth line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD 기본 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFile = sc.textFile('example.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line 수 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFile.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫번째 줄 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textFile.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특정 text를 포함하는 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secfind = textFile.filter(lambda line: 'second' in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD, 아직까지 어떠한 연산도 이루어지지 않은 상태입니다!\n",
    "secfind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이때 연산 시작\n",
    "secfind.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이때 연산 시작\n",
    "secfind.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD에서의 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile example2.txt\n",
    "first \n",
    "second line\n",
    "the third line\n",
    "then a fourth line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = sc.textFile('example2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map과 Flatmap의 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd.map(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect everything as a single flat map\n",
    "text_rdd.flatMap(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV 파일 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.map(lambda x: x.split(\",\")).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.map(lambda x: x.replace(\" \",\"_\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.map(lambda x: x.replace(\" \",\"_\")).map(lambda x: x.replace(\"'\",\"_\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdd.map(lambda x: x.replace(\" \",\"_\")).map(lambda x: x.replace(\"'\",\"_\")).map(lambda x: x.replace(\"/\",\"_\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rdd = rdd.map(lambda x: x.replace(\" \",\"_\").replace(\"'\",\"_\").replace(\"/\",\"_\").replace('\"',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rdd = clean_rdd.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group BY 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rdd.map(lambda lst: (lst[0],lst[-1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 원소(lst[0])를 키로 인지\n",
    "clean_rdd.map(lambda lst: (lst[0],lst[-1]))\\\n",
    "         .reduceByKey(lambda value1,value2 : value1+value2)\\\n",
    "         .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 올바른 연산을 위해 Float으로 캐스팅\n",
    "clean_rdd.map(lambda lst: (lst[0],lst[-1]))\\\n",
    "         .reduceByKey(lambda value1,value2 : float(value1)+float(value2))\\\n",
    "         .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 코드\n",
    "clean_rdd.map(lambda lst: (lst[0],lst[-1]))\\\n",
    ".reduceByKey(lambda value1,value2 : float(value1)+float(value2))\\\n",
    ".filter(lambda x: not x[0]=='gender')\\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균은 어떻게 구할 수 있을까?\n",
    "\n",
    "clean_rdd.map(lambda lst: (lst[0],(lst[-1],1)))\\\n",
    ".reduceByKey(lambda value1, value2 : ((float(value1[0])+float(value2[0])), int(value1[1])+int(value2[1])))\\\n",
    ".filter(lambda x: not x[0]=='gender')\\\n",
    ".mapValues(lambda x: x[0]/x[1])\\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "appName = \"Python Example - PySpark Read CSV\"\n",
    "master = 'local'\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(master) \\\n",
    "    .appName(appName) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Convert list to data frame\n",
    "df = spark.read.format('csv') \\\n",
    "                .option('header',True) \\\n",
    "                .option('multiLine', True) \\\n",
    "                .load('data.csv')\n",
    "df.show()\n",
    "print(f'Record count is: {df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('gender').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('gender').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('race/ethnicity').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.groupBy(\"gender\").agg(F.mean('writing score'), F.mean('math score')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
